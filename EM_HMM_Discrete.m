function [ model ] = EM_HMM_Discrete(X,pi,B,A,Max_iter)
%%  perform the EM algorithm to estimate the parameters for discrete case 
%input:
%   X:  set of observations generated by the HMM Generate Data functions 
%   pi: probability  hidden state.
%   B: Emmision Probability Matrix
%   A: transition matrix
%return:
%    model.pi prpbility of hiddent variables.
%    model.A new transition matrix 
%    model.B emmision matrix
%    model.loglike is the final loglikelihood of evaluation.
%



[N,T] = size(X);% N: number of sequences T: length of sequences
[K,J]=size(B)%% number of hidden variables attributes 

% random initialization
pi = rand(K,1)+eps; 
pi = pi /sum(pi);

A= rand(K,K)+eps; 
A = bsxfun(@times,A,1./sum(A,2));

B= rand(K,J)+eps; 
B = bsxfun(@times,B,1./sum(B,2));
    
loglike=zeros(1,Max_iter);
epsilon=10e-7 %% convergence limit
for iteration = 1:Max_iter 
    iteration
   %initialise
    pi_new =0 .* pi;
    A_new = 0 .* A;
    B_new = 0 .* B;
    
    for index = 1:N 
        %% calculate the alpha using the random/last update parameterss A,B,pi to recal expectations
       [alpha,scale,logp_X_T]=Forwards(A,B,X,pi,index,K,T);
       beta=backwards(A,B,X,index,K,T,scale);
        
%         E-step: calculate expectations

          gamma=alpha.*beta;% smooth posterior p(zt|x1:T)
          %normalise
          gamma = bsxfun(@times,gamma,1./sum(gamma));
          
          %two-slice joint smooth posterior
          %eps_joint=joint_prob(X,A,B,alpha, beta,index);
          
           % compute expectation regards to posterior of states at t,t+1.
            joint = A .* 0;
            for t = 1:T-1
                temp = (alpha(:,t) * (beta(:,t+1) .* B(:,X(index,t+1)))' ).* A;
                joint= joint + temp./ sum(sum(temp));
            end
            
        %% M-step update parameters to maximise
          pi_new = pi_new + gamma(:,1);
          A_new = A_new +joint;        
         % for each hiddent states j, sum over the probability of gamma
         % given one observation x
          for j = 1:J
           B_new(:,j) = B_new(:,j) + sum(gamma(:,X(index,:)==j),2);
          end
           % evaluate log-likelihood
          % loglike(iteration) = loglike(iteration)+sum(logp_X_T);
           loglike(iteration) = loglike(iteration)-sum(scale);

     end
          
          % normalise
          pi= sum(A_new,2);
          pi = pi/ sum(pi);
          A = bsxfun(@times,A_new,1./sum(A_new,2));
          B = bsxfun(@times,B_new,1./sum(B_new,2));
    
         
          % check if it converges - stops changing
           
          if  iteration>=2 
              convergence= abs(1-loglike(iteration-1)/loglike(iteration));
              if convergence<epsilon 
                  break;
              end 
          end    
    
    end
    model.pi = pi;
    model.A = A;
    model.B = B;
    model.loglike= loglike(iteration);
    plot(loglike);
end




function [alpha,scale,logp_X_T]=Forwards(A,B,X,pi,i,K,T)
%%Forward - alpha 
  % compute recursively the posterior density p(zt|x1:t) 
  %input:
  % A transition matrix 
  % B emission probability vector
  % X observations
  % pi initial state distribution
  % i: sample index,i th sample among the N observations
  % K: state numbers
  % T: time length.
  %output: 
  %alpha
  %Z:log probablity of the evidence logp(X 1:T)
   alpha=zeros(K,T);
  % initial step:
   b1=B(:,X(i,1)); %% emission probility for sample i at time 1
   alpha(:,1)= (b1.*pi); %%p()
   Z(1)=sum(alpha(:,1));
   scale(1)=1./Z(1);
   %normalise
   alpha(:,1) = alpha(:,1)/scale(1);
   logp_X_T=log(Z(1)); 
   % predict-update cycle.
   for t = 2:T
        bt=B(:,X(i,t));
        alpha(:,t)=bt.*(A'* alpha(:,t-1));
        Z(t)=sum(alpha(:,t));
        scale(t)=1./Z(t);
        %belief state at time t
        alpha(:,t) = alpha(:,t)*scale(t); %%normalise       
        logp_X_T=logp_X_T+log(Z(t));          
   end 
 
end

function [beta]=backwards(A,B,X,i,K,T,scale_alpha)
%%backwards - beta 
  % compute recursively the conditonal likelihood of future evidence given
  % that the hidden state at time t is j
  %input:
  % A transition matrix 
  % B emission probability vector
  % X observations
  % pi initial state distribution
  % i: sample index,i th sample among the N observations
  % K: state numbers
  % T: time length.
  %output: 
  %beta
 % initial step:
   beta=ones(K,T); 
   % step-back cycle.
   for t= T-1:-1:1
        bt=B(:,X(i,t+1));%% next time emission probablity
        beta(:,t)=A*(bt.*beta(:,t+1)); 
        % in case of underflow 
        beta(:,t)=beta(:,t)*scale_alpha(t);
   end 
 
end



function eps = joint_prob(X,A,B,alpha, beta,index)
[~,T] = size(X);% time length
[~,K] = size(B);% hidden states
eps =zeros(2,2);
    for t = 1:T-1
        j=X(index,t+1); %% get the observations x state at time t+1     
        temp=alpha(:,t)*(B(:,j).*beta(:,t+1))';%% calculate the 2-period 
        if t==1
              eps=A.*temp;
        else
         eps=[eps,A.*temp];%% concate the 2-period joint prob. length: (T-1)* 2 
        end
    end
end